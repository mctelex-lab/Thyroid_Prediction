{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3705eb-f803-46b5-bdbf-d34d8952e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, cohen_kappa_score\n",
    "import pickle  # For saving models\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('C:/Users/CSE/Desktop/Data/Thyroid/hypothyroid.csv')\n",
    "\n",
    "# Encode categorical variables using LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        data[column] = enc.fit_transform(data[column])\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# Normalize numerical features\n",
    "for col in ['age', 'TT4', 'T4U', 'FTI']:\n",
    "    data[col] = (data[col] - data[col].min()) / (data[col].max() - data[col].min())\n",
    "\n",
    "# Visualize class distribution of target variable before balancing\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data['binaryClass'])\n",
    "plt.title('Class Distribution of Target Variable (Before Balancing)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.show()\n",
    "\n",
    "# Augment the dataset to reach 1000 instances using ADASYN\n",
    "if len(data) < 5000:\n",
    "    ada = ADASYN(sampling_strategy=0.5)  # Adjust sampling_strategy as needed\n",
    "    while len(data) < 1000:\n",
    "        x_aug, y_aug = ada.fit_resample(data.drop('binaryClass', axis=1), data['binaryClass'])\n",
    "        aug_data = pd.DataFrame(x_aug, columns=data.drop('binaryClass', axis=1).columns)\n",
    "        aug_data['binaryClass'] = y_aug\n",
    "        data = pd.concat([data, aug_data], ignore_index=True)\n",
    "\n",
    "# Visualize class distribution of target variable after augmentation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data['binaryClass'])\n",
    "plt.title('Class Distribution of Target Variable (After Augmentation)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.show()\n",
    "\n",
    "# Apply ADASYN for oversampling and RandomUnderSampler for undersampling\n",
    "ada = ADASYN(sampling_strategy='minority')\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# Apply ADASYN and undersampling to the entire dataset\n",
    "x_balanced, y_balanced = ada.fit_resample(data.drop('binaryClass', axis=1), data['binaryClass'])\n",
    "x_balanced, y_balanced = rus.fit_resample(x_balanced, y_balanced)\n",
    "\n",
    "# Visualize class distribution of target variable after balancing\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(y_balanced)\n",
    "plt.title('Class Distribution of Target Variable (After Balancing)')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "plt.show()\n",
    "\n",
    "# Split balanced data into training and test sets\n",
    "x_train_balanced, x_test_balanced, y_train_balanced, y_test_balanced = train_test_split(x_balanced, y_balanced, test_size=0.2, stratify=y_balanced)\n",
    "\n",
    "# Split original data into training and test sets\n",
    "x = data.drop('binaryClass', axis=1)\n",
    "y = data['binaryClass']\n",
    "x_train_orig, x_test_orig, y_train_orig, y_test_orig = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Neural Networks': MLPClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True),  # Enable probability estimation for ROC curves\n",
    "    'J48 (Decision Tree)': DecisionTreeClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "# Storage dictionaries for results\n",
    "results_orig = {}\n",
    "results_balanced = {}\n",
    "\n",
    "# Evaluate classifiers before and after balancing\n",
    "for name, classifier in classifiers.items():\n",
    "    results_orig[name] = {}\n",
    "    results_balanced[name] = {}\n",
    "    \n",
    "    # Fit classifier on original training data\n",
    "    classifier.fit(x_train_orig, y_train_orig)\n",
    "    predictions_orig = classifier.predict(x_test_orig)\n",
    "    accuracy_orig = accuracy_score(y_test_orig, predictions_orig)\n",
    "    kappa_orig = cohen_kappa_score(y_test_orig, predictions_orig)\n",
    "    results_orig[name]['accuracy'] = accuracy_orig\n",
    "    results_orig[name]['kappa'] = kappa_orig\n",
    "    results_orig[name]['classification_report'] = classification_report(y_test_orig, predictions_orig, target_names=['Negative', 'Positive'])\n",
    "    \n",
    "    # Save the trained model for original data\n",
    "    with open(f'{name}_orig_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "    \n",
    "    # Plot confusion matrix for original data\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    cm_orig = confusion_matrix(y_test_orig, predictions_orig)\n",
    "    sns.heatmap(cm_orig, annot=True, cmap='Blues', fmt='g', cbar=False,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {name} (Original)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute ROC curve for original data\n",
    "    y_score_orig = classifier.predict_proba(x_test_orig)[:, 1]\n",
    "    fpr_orig, tpr_orig, _ = roc_curve(y_test_orig, y_score_orig)\n",
    "    roc_auc_orig = auc(fpr_orig, tpr_orig)\n",
    "    \n",
    "    # Store ROC results for original data\n",
    "    results_orig[name]['fpr'] = fpr_orig\n",
    "    results_orig[name]['tpr'] = tpr_orig\n",
    "    results_orig[name]['roc_auc'] = roc_auc_orig\n",
    "    \n",
    "    # Fit classifier on balanced training data\n",
    "    classifier.fit(x_train_balanced, y_train_balanced)\n",
    "    predictions_balanced = classifier.predict(x_test_balanced)\n",
    "    accuracy_balanced = accuracy_score(y_test_balanced, predictions_balanced)\n",
    "    kappa_balanced = cohen_kappa_score(y_test_balanced, predictions_balanced)\n",
    "    results_balanced[name]['accuracy'] = accuracy_balanced\n",
    "    results_balanced[name]['kappa'] = kappa_balanced\n",
    "    results_balanced[name]['classification_report'] = classification_report(y_test_balanced, predictions_balanced, target_names=['Negative', 'Positive'])\n",
    "    \n",
    "    # Save the trained model for balanced data\n",
    "    with open(f'{name}_balanced_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(classifier, model_file)\n",
    "    \n",
    "    # Plot confusion matrix after balancing\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    cm_balanced = confusion_matrix(y_test_balanced, predictions_balanced)\n",
    "    sns.heatmap(cm_balanced, annot=True, cmap='Blues', fmt='g', cbar=False,\n",
    "                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix - {name} (Balanced)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Compute ROC curve after balancing\n",
    "    y_score_balanced = classifier.predict_proba(x_test_balanced)[:, 1]\n",
    "    fpr_balanced, tpr_balanced, _ = roc_curve(y_test_balanced, y_score_balanced)\n",
    "    roc_auc_balanced = auc(fpr_balanced, tpr_balanced)\n",
    "    \n",
    "    # Store ROC results after balancing\n",
    "    results_balanced[name]['fpr'] = fpr_balanced\n",
    "    results_balanced[name]['tpr'] = tpr_balanced\n",
    "    results_balanced[name]['roc_auc'] = roc_auc_balanced\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Classifier: {name}')\n",
    "    print('Classification Report Before Balancing:')\n",
    "    print(results_orig[name]['classification_report'])\n",
    "    print(f'Accuracy Before Balancing: {accuracy_orig:.4f}, Kappa Before Balancing: {kappa_orig:.4f}')\n",
    "    \n",
    "    print('Classification Report After Balancing:')\n",
    "    print(results_balanced[name]['classification_report'])\n",
    "    print(f'Accuracy After Balancing: {accuracy_balanced:.4f}, Kappa After Balancing: {kappa_balanced:.4f}')\n",
    "    print('-' * 50)\n",
    "\n",
    "# Plot ROC curves before balancing\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "for name, result in results_orig.items():\n",
    "    plt.plot(result['fpr'], result['tpr'], lw=2, label=f'{name} (AUC = {result[\"roc_auc\"]:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (Before Balancing)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curves after balancing\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "for name, result in results_balanced.items():\n",
    "    plt.plot(result['fpr'], result['tpr'], lw=2, label=f'{name} (AUC = {result[\"roc_auc\"]:.2f})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (After Balancing)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
